{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a4b4e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all the required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from textblob import TextBlob\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB,MultinomialNB,BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c9b3338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Text</th>\n",
       "      <th>Username</th>\n",
       "      <th>Like Count</th>\n",
       "      <th>Retweet Count</th>\n",
       "      <th>Follower Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-12-30 16:00:48+00:00</td>\n",
       "      <td>Love the #Nestle tvc on ... Really awesome</td>\n",
       "      <td>Dominication</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>366.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-12-30 10:20:53+00:00</td>\n",
       "      <td>RT @bmi_cfw: L'Oreal Continues To Work With #N...</td>\n",
       "      <td>BMIResearch</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17221.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-12-29 06:00:08+00:00</td>\n",
       "      <td>*HOT* #Nestle Nesquik $1.25 Off #Coupon http:/...</td>\n",
       "      <td>maritramos</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7771.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-12-28 22:01:24+00:00</td>\n",
       "      <td>Oatmeal Scotchies!!! Best cookies ever! http:/...</td>\n",
       "      <td>megansmunchies</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1811.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-12-28 18:51:03+00:00</td>\n",
       "      <td>RT @ameliatimbers U.S. #Muslims : A New #Consu...</td>\n",
       "      <td>AndresTTapia</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3291.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Date  \\\n",
       "0  2010-12-30 16:00:48+00:00   \n",
       "1  2010-12-30 10:20:53+00:00   \n",
       "2  2010-12-29 06:00:08+00:00   \n",
       "3  2010-12-28 22:01:24+00:00   \n",
       "4  2010-12-28 18:51:03+00:00   \n",
       "\n",
       "                                                Text        Username  \\\n",
       "0         Love the #Nestle tvc on ... Really awesome    Dominication   \n",
       "1  RT @bmi_cfw: L'Oreal Continues To Work With #N...     BMIResearch   \n",
       "2  *HOT* #Nestle Nesquik $1.25 Off #Coupon http:/...      maritramos   \n",
       "3  Oatmeal Scotchies!!! Best cookies ever! http:/...  megansmunchies   \n",
       "4  RT @ameliatimbers U.S. #Muslims : A New #Consu...    AndresTTapia   \n",
       "\n",
       "   Like Count  Retweet Count  Follower Count  \n",
       "0         0.0            0.0           366.0  \n",
       "1         0.0            0.0         17221.0  \n",
       "2         0.0            1.0          7771.0  \n",
       "3         0.0            0.0          1811.0  \n",
       "4         0.0            1.0          3291.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('Nestle big boi.csv',encoding='ISO-8859-1')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e14679e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Username column\n",
    "df.drop('Username',inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7536d00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date               30\n",
       "Text               80\n",
       "Like Count        160\n",
       "Retweet Count     240\n",
       "Follower Count    240\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check any missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a578148e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date : 0.017480887562931195 %\n",
      "Text : 0.04661570016781652 %\n",
      "Like Count : 0.09323140033563304 %\n",
      "Retweet Count : 0.13984710050344956 %\n",
      "Follower Count : 0.13984710050344956 %\n"
     ]
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "    print(col,':',(df[col].isnull().sum()/len(df))*100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12ed97c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "171376"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the missing values as its count is very less compared to the entire dataset\n",
    "df.dropna(inplace=True)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d79b6b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Maggi: 17046\n",
      "#Nestle: 16270\n",
      "#maggi: 12125\n",
      "#nestle: 10305\n",
      "#boost: 8378\n",
      "#smarties: 8357\n",
      "#kitkat: 7519\n",
      "#nespresso: 7143\n",
      "#Nespresso: 6943\n",
      "#coffee: 6938\n",
      "#carnation: 6923\n",
      "#NestleIndia: 6415\n",
      "#nescafe: 6334\n",
      "#Nestl√É: 5692\n",
      "#Nescafe: 5520\n",
      "#DolceGusto: 5421\n",
      "#KitKat: 5171\n",
      "#dolcegusto: 5100\n",
      "#Carnation: 4725\n",
      "#Smarties: 4301\n"
     ]
    }
   ],
   "source": [
    "# extract hashtags from the Text column\n",
    "hashtags = []\n",
    "for text in df['Text']:\n",
    "    hashtags += re.findall(r'#\\w+', text)\n",
    "\n",
    "# count the frequency of each hashtag\n",
    "freq = Counter(hashtags)\n",
    "\n",
    "# sort the hashtags by frequency\n",
    "sorted_hashtags = sorted(freq.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# extract the top 20 hashtags\n",
    "top_20_hashtags = sorted_hashtags[:20]\n",
    "\n",
    "# print the top 20 hashtags with their frequency\n",
    "for hashtag, count in top_20_hashtags:\n",
    "    print(f\"{hashtag}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eefd9e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove URLs, mentions, and hashtags\n",
    "def remove_twitter_elements(tweet):\n",
    "    tweet = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', tweet, flags=re.MULTILINE)\n",
    "    tweet = re.sub(r'\\@\\w+|\\#','', tweet)\n",
    "    return tweet\n",
    "\n",
    "df['Text'] = df['Text'].apply(remove_twitter_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42b78a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing emojis\n",
    "def remove_emojis(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n",
    "df['Text'] = df['Text'].apply(remove_emojis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa9be6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing punctuations\n",
    "def remove_punctuation(text):\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    return text.translate(translator)\n",
    "\n",
    "df['Text'] = df['Text'].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06d87c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove special characters \n",
    "def remove_special_characters(tweet):\n",
    "    tweet = re.sub('[^a-zA-Z0-9\\s]', '', tweet)\n",
    "    return tweet\n",
    "\n",
    "df['Text'] = df['Text'].apply(remove_special_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f055f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting to lowercase\n",
    "df['Text'] = df['Text'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd968e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text\n",
    "def tokenize(tweet):\n",
    "    tokens = nltk.word_tokenize(tweet)\n",
    "    return tokens\n",
    "\n",
    "df['Text'] = df['Text'].apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3ad3d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stop words\n",
    "def remove_stop_words(tokens):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_tokens = [token for token in tokens if token.lower() not in stop_words]\n",
    "    return filtered_tokens\n",
    "\n",
    "df['Text'] = df['Text'].apply(remove_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a4bdfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemming or Lemmatization\n",
    "def stem_tokens(tokens):\n",
    "    stemmer = SnowballStemmer('english')\n",
    "    stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
    "    return stemmed_tokens\n",
    "\n",
    "df['Text'] = df['Text'].apply(stem_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21958426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize case\n",
    "def normalize_case(tokens):\n",
    "    normalized_tokens = [token.lower() for token in tokens]\n",
    "    return normalized_tokens\n",
    "\n",
    "df['Text'] = df['Text'].apply(normalize_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5666d785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join tokens back into a single string\n",
    "def join_text(tweet):\n",
    "    joined_tweet = \" \".join(tweet)\n",
    "    return joined_tweet\n",
    "\n",
    "df['Text'] = df['Text'].apply(join_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff8b7b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date to extract Year, Month, Day\n",
    "df['Date']=pd.to_datetime(df['Date'])\n",
    "\n",
    "df['Year'] = df['Date'].apply(lambda date:date.year)\n",
    "df['Month'] = df['Date'].apply(lambda date:date.month)\n",
    "df['Day']=df['Date'].apply(lambda date:date.day)\n",
    "df['Date'] = df['Date'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8d961719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Text</th>\n",
       "      <th>Like Count</th>\n",
       "      <th>Retweet Count</th>\n",
       "      <th>Follower Count</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-12-30</td>\n",
       "      <td>love nestl tvc realli awesom</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>366.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-12-30</td>\n",
       "      <td>rt loreal continu work nestl time analyst pond...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17221.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-12-29</td>\n",
       "      <td>hot nestl nesquik 125 coupon printablecoupon c...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7771.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-12-28</td>\n",
       "      <td>oatmeal scotchi best cooki ever nestl</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1811.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-12-28</td>\n",
       "      <td>rt us muslim new consum nich nestl increas hal...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3291.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date                                               Text  Like Count  \\\n",
       "0  2010-12-30                       love nestl tvc realli awesom         0.0   \n",
       "1  2010-12-30  rt loreal continu work nestl time analyst pond...         0.0   \n",
       "2  2010-12-29  hot nestl nesquik 125 coupon printablecoupon c...         0.0   \n",
       "3  2010-12-28              oatmeal scotchi best cooki ever nestl         0.0   \n",
       "4  2010-12-28  rt us muslim new consum nich nestl increas hal...         0.0   \n",
       "\n",
       "   Retweet Count  Follower Count  Year  Month  Day  \n",
       "0            0.0           366.0  2010     12   30  \n",
       "1            0.0         17221.0  2010     12   30  \n",
       "2            1.0          7771.0  2010     12   29  \n",
       "3            0.0          1811.0  2010     12   28  \n",
       "4            1.0          3291.0  2010     12   28  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2bb289d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to get the polarity of a tweet\n",
    "def get_tweet_polarity(tweet):\n",
    "    blob = TextBlob(tweet)\n",
    "    polarity = blob.sentiment.polarity\n",
    "    if polarity > 0.05:\n",
    "        return 'positive'\n",
    "    elif polarity < -0.05:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "\n",
    "# add a polarity column to the DataFrame\n",
    "df['polarity'] = df['Text'].apply(get_tweet_polarity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2fc22545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Text</th>\n",
       "      <th>Like Count</th>\n",
       "      <th>Retweet Count</th>\n",
       "      <th>Follower Count</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-12-30</td>\n",
       "      <td>love nestl tvc realli awesom</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>366.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-12-30</td>\n",
       "      <td>rt loreal continu work nestl time analyst pond...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17221.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-12-29</td>\n",
       "      <td>hot nestl nesquik 125 coupon printablecoupon c...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7771.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-12-28</td>\n",
       "      <td>oatmeal scotchi best cooki ever nestl</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1811.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-12-28</td>\n",
       "      <td>rt us muslim new consum nich nestl increas hal...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3291.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date                                               Text  Like Count  \\\n",
       "0  2010-12-30                       love nestl tvc realli awesom         0.0   \n",
       "1  2010-12-30  rt loreal continu work nestl time analyst pond...         0.0   \n",
       "2  2010-12-29  hot nestl nesquik 125 coupon printablecoupon c...         0.0   \n",
       "3  2010-12-28              oatmeal scotchi best cooki ever nestl         0.0   \n",
       "4  2010-12-28  rt us muslim new consum nich nestl increas hal...         0.0   \n",
       "\n",
       "   Retweet Count  Follower Count  Year  Month  Day  polarity  \n",
       "0            0.0           366.0  2010     12   30  positive  \n",
       "1            0.0         17221.0  2010     12   30   neutral  \n",
       "2            1.0          7771.0  2010     12   29  positive  \n",
       "3            0.0          1811.0  2010     12   28  positive  \n",
       "4            1.0          3291.0  2010     12   28  positive  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af032736",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fbf09bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf=TfidfVectorizer(max_features=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5fae7fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=tfidf.fit_transform(df['Text']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "75eb3ed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(171376, 3000)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "74d206fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the target variable\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(df['polarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f11730d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 2, ..., 1, 1, 2])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6dbd2dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e804f11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb=GaussianNB()\n",
    "mnb=MultinomialNB()\n",
    "bnb=BernoulliNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cf3385ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of Gaussian NB: 0.3936865445209476\n",
      "Confusion matrix of Gaussian NB:\n",
      "[[ 2720    50   127]\n",
      " [12742  4351  2150]\n",
      " [ 5466   247  6423]]\n"
     ]
    }
   ],
   "source": [
    "#Gaussian Naive Bayes\n",
    "gnb.fit(X_train,y_train)\n",
    "y_pred1=gnb.predict(X_test)\n",
    "print('Accuracy score of Gaussian NB:',accuracy_score(y_test,y_pred1))\n",
    "print('Confusion matrix of Gaussian NB:')\n",
    "print(confusion_matrix(y_test,y_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "447efccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of Multinomial NB: 0.8714260707200373\n",
      "Confusion matrix of Multinomial NB:\n",
      "[[  903  1578   416]\n",
      " [   40 18413   790]\n",
      " [   13  1570 10553]]\n"
     ]
    }
   ],
   "source": [
    "#Multinomial Naive Bayes\n",
    "mnb.fit(X_train,y_train)\n",
    "y_pred2=mnb.predict(X_test)\n",
    "print('Accuracy score of Multinomial NB:',accuracy_score(y_test,y_pred2))\n",
    "print('Confusion matrix of Multinomial NB:')\n",
    "print(confusion_matrix(y_test,y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c0e6b9a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of Bernoulli NB: 0.8856050881082973\n",
      "Confusion matrix of Bernoulli NB:\n",
      "[[ 1783   750   364]\n",
      " [  468 17174  1601]\n",
      " [  139   599 11398]]\n"
     ]
    }
   ],
   "source": [
    "#Bernoulli Naive Bayes\n",
    "bnb.fit(X_train,y_train)\n",
    "y_pred3=bnb.predict(X_test)\n",
    "print('Accuracy score of Bernoulli NB:',accuracy_score(y_test,y_pred3))\n",
    "print('Confusion matrix of Bernoulli NB:')\n",
    "print(confusion_matrix(y_test,y_pred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "51841f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Nestle Preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77f35d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6190905",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
